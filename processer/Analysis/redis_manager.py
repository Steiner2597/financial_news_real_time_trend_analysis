import json
import redis
import os
from datetime import datetime
from config import CONFIG


class RedisManager:
    def __init__(self):
        # Redisè¿æ¥é…ç½®
        self.redis_host = CONFIG["redis"]["host"]
        self.redis_port = CONFIG["redis"]["port"]
        self.redis_password = CONFIG["redis"]["password"]
        self.output_prefix = CONFIG["redis"]["output_prefix"]
        self.key_ttl = CONFIG["redis"]["key_ttl_seconds"]
        
        # è¾“å…¥æ•°æ®åº“é…ç½®ï¼ˆä» Cleaner è¯»å–ï¼‰
        self.input_db = CONFIG["redis"]["input_db"]  # DB1
        # è¾“å‡ºæ•°æ®åº“é…ç½®ï¼ˆå†™å…¥å¤„ç†ç»“æœï¼‰
        self.output_db = CONFIG["redis"]["output_db"]  # DB2

        # è¿æ¥ä¸¤ä¸ªæ•°æ®åº“
        self.r_input = self._connect_redis(self.input_db, "è¾“å…¥")  # ä» DB1 è¯»å–
        self.r = self._connect_redis(self.output_db, "è¾“å‡º")  # å†™å…¥ DB2ï¼ˆä¿æŒå…¼å®¹æ€§ï¼‰

    def _connect_redis(self, db, db_name=""):
        """è¿æ¥ Redis æ•°æ®åº“"""
        try:
            r = redis.Redis(
                host=self.redis_host,
                port=self.redis_port,
                db=db,
                password=self.redis_password,
                decode_responses=True
            )
            r.ping()
            print(f"âœ… Redis {db_name}è¿æ¥æˆåŠŸ (DB{db})")
            return r
        except redis.ConnectionError as e:
            print(f"âŒ Redis {db_name}è¿æ¥å¤±è´¥: {e}")
            return None

    def save_raw_data_to_local(self, filename=None):
        """ä»Redisè·å–åŸå§‹æ•°æ®å¹¶ä¿å­˜åˆ°æœ¬åœ°format_conversionæ–‡ä»¶å¤¹"""
        if not self.r:
            print("Redisæœªè¿æ¥ï¼Œæ— æ³•è·å–æ•°æ®")
            return False

        try:
            # è¿™é‡Œå‡è®¾åŸå§‹æ•°æ®å­˜å‚¨åœ¨ä¸€ä¸ªç‰¹å®šçš„é”®ä¸­
            # æ‚¨å¯èƒ½éœ€è¦æ ¹æ®å®é™…æƒ…å†µè°ƒæ•´è¿™ä¸ªé”®å
            raw_data_key = "raw_financial_data"
            raw_data = self.r.get(raw_data_key)

            if not raw_data:
                print(f"Redisä¸­æ²¡æœ‰æ‰¾åˆ°åŸå§‹æ•°æ®é”®: {raw_data_key}")
                return False

            # è§£æJSONæ•°æ®
            data = json.loads(raw_data)

            # åˆ›å»ºformat_conversionæ–‡ä»¶å¤¹ï¼ˆå¦‚æœä¸å­˜åœ¨ï¼‰
            conversion_dir = "Format conversion"
            if not os.path.exists(conversion_dir):
                os.makedirs(conversion_dir)

            # ç”Ÿæˆæ–‡ä»¶å
            if filename is None:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"input_data_{timestamp}.jsonl"
            else:
                # ç¡®ä¿æ˜¯jsonlæ ¼å¼
                if not filename.endswith('.jsonl'):
                    filename = filename.replace('.json', '.jsonl')

            filepath = os.path.join(conversion_dir, filename)

            # ä¿å­˜åˆ°æœ¬åœ°æ–‡ä»¶
            with open(filepath, 'w', encoding='utf-8') as f:
                # å¦‚æœæ˜¯åˆ—è¡¨ï¼Œé€è¡Œå†™å…¥
                if isinstance(data, list):
                    for item in data:
                        f.write(json.dumps(item, ensure_ascii=False) + '\n')
                else:
                    # å¦‚æœæ˜¯å•ä¸ªå¯¹è±¡ï¼Œç›´æ¥å†™å…¥
                    f.write(json.dumps(data, ensure_ascii=False))

            print(f"åŸå§‹æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
            return filepath

        except Exception as e:
            print(f"ä¿å­˜åŸå§‹æ•°æ®æ—¶å‡ºé”™: {e}")
            return False

    def publish_processed_data(self, output_file_path=None):
        """
        å°†å¤„ç†åçš„æ•°æ®å‘å¸ƒåˆ° Redis
        
        ä½¿ç”¨ String ç»“æ„ï¼ˆè€Œé Hashï¼‰ç¡®ä¿ä¸ Visualization å…¼å®¹
        """
        if not self.r:
            print("âŒ Redis æœªè¿æ¥ï¼Œæ— æ³•å‘å¸ƒæ•°æ®")
            return False

        try:
            # è¯»å–å¤„ç†åçš„æ•°æ®
            if output_file_path is None:
                output_file_path = "output_data.json"

            with open(output_file_path, 'r', encoding='utf-8') as f:
                processed_data = json.load(f)

            # æ·»åŠ å‘å¸ƒæ—¶é—´æˆ³ - âœ… ISO 8601 æ ¼å¼ï¼Œå¸¦ UTC æ—¶åŒºæ ‡è®°
            processed_data['metadata']['redis_publish_time'] = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")

            # ==================== ä½¿ç”¨ String ç»“æ„å­˜å‚¨ ====================
            # è¿™æ · Visualization å¯ä»¥é€šè¿‡ redis.get("processed_data:metadata") è¯»å–
            
            print("\nğŸ“¤ å‘å¸ƒå¤„ç†åçš„æ•°æ®åˆ° Redis...")
            
            # 1. å‘å¸ƒå…ƒæ•°æ®
            metadata_key = f"{self.output_prefix}:metadata"
            self.r.set(
                metadata_key,
                json.dumps(processed_data['metadata'], ensure_ascii=False)
            )
            self.r.expire(metadata_key, self.key_ttl)
            print(f"  âœ“ {metadata_key}")

            # 2. å‘å¸ƒçƒ­è¯æ•°æ®
            keywords_key = f"{self.output_prefix}:trending_keywords"
            self.r.set(
                keywords_key,
                json.dumps(processed_data['trending_keywords'], ensure_ascii=False)
            )
            self.r.expire(keywords_key, self.key_ttl)
            print(f"  âœ“ {keywords_key}")

            # 3. å‘å¸ƒè¯äº‘æ•°æ®
            wordcloud_key = f"{self.output_prefix}:word_cloud"
            self.r.set(
                wordcloud_key,
                json.dumps(processed_data['word_cloud'], ensure_ascii=False)
            )
            self.r.expire(wordcloud_key, self.key_ttl)
            print(f"  âœ“ {wordcloud_key}")

            # 4. å‘å¸ƒæ–°é—»æ•°æ®
            news_key = f"{self.output_prefix}:news_feed"
            self.r.set(
                news_key,
                json.dumps(processed_data['news_feed'], ensure_ascii=False)
            )
            self.r.expire(news_key, self.key_ttl)
            print(f"  âœ“ {news_key}")

            # 5. å‘å¸ƒå†å²æ•°æ®
            history_data = processed_data.get('history_data', {})
            for keyword, data in history_data.items():
                history_key = f"{self.output_prefix}:history_data:{keyword}"
                self.r.set(
                    history_key,
                    json.dumps(data, ensure_ascii=False)
                )
                self.r.expire(history_key, self.key_ttl)
            
            print(f"  âœ“ {len(history_data)} æ¡å†å²æ•°æ®")

            # å¯é€‰ï¼šå‘å¸ƒé€šçŸ¥æ¶ˆæ¯
            if "publish_channel" in CONFIG["redis"]:
                channel = CONFIG["redis"]["publish_channel"]
                self.r.publish(channel, json.dumps({
                    "event": "data_updated",
                    "timestamp": datetime.now().isoformat(),
                    "keywords_count": len(processed_data['trending_keywords']),
                    "history_count": len(history_data)
                }))
                print(f"  âœ“ å‘å¸ƒæ›´æ–°é€šçŸ¥åˆ° {channel}")

            print("âœ… æ‰€æœ‰æ•°æ®å·²æˆåŠŸå‘å¸ƒåˆ° Redis (DB0)")
            return True

        except FileNotFoundError:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {output_file_path}")
            return False
        except Exception as e:
            print(f"âŒ å‘å¸ƒæ•°æ®æ—¶å‡ºé”™: {e}")
            import traceback
            traceback.print_exc()
    def get_processed_data(self) -> dict:
        """ä» Redis è¯»å–å¤„ç†åçš„æ•°æ®ï¼ˆéªŒè¯ï¼‰"""
        if not self.r:
            print("âŒ Redis æœªè¿æ¥")
            return None

        try:
            metadata_key = f"{self.output_prefix}:metadata"
            metadata_json = self.r.get(metadata_key)
            
            if not metadata_json:
                print(f"âš ï¸  Redis ä¸­æœªæ‰¾åˆ°æ•°æ®ï¼ˆé”®ï¼š{metadata_key}ï¼‰")
                return None

            keywords_json = self.r.get(f"{self.output_prefix}:trending_keywords")
            wordcloud_json = self.r.get(f"{self.output_prefix}:word_cloud")
            news_json = self.r.get(f"{self.output_prefix}:news_feed")

            result = {
                "metadata": json.loads(metadata_json) if metadata_json else {},
                "trending_keywords": json.loads(keywords_json) if keywords_json else [],
                "word_cloud": json.loads(wordcloud_json) if wordcloud_json else [],
                "news_feed": json.loads(news_json) if news_json else []
            }

            print(f"âœ… æˆåŠŸè¯»å–å¤„ç†æ•°æ®ï¼š{len(result['trending_keywords'])} ä¸ªçƒ­è¯")
            return result

        except Exception as e:
            print(f"âŒ è¯»å–å¤„ç†æ•°æ®å¤±è´¥: {e}")
            return None

    def verify_redis_connection(self) -> bool:
        """éªŒè¯ Redis è¿æ¥"""
        if self.r:
            try:
                self.r.ping()
                info = self.r.info()
                print(f"âœ… Redis å·²è¿æ¥ (è¾“å‡ºDB{self.output_db})")
                print(f"   Redis ç‰ˆæœ¬: {info.get('redis_version')}")
                print(f"   å·²è¿æ¥å®¢æˆ·ç«¯: {info.get('connected_clients')}")
                print(f"   å·²ç”¨å†…å­˜: {info.get('used_memory_human')}")
                return True
            except Exception as e:
                print(f"âŒ Redis è¿æ¥å·²æ–­å¼€: {e}")
                return False
        return False

    def check_output_keys(self) -> dict:
        """æ£€æŸ¥è¾“å‡ºé”®æ˜¯å¦å­˜åœ¨"""
        if not self.r:
            return {}
        
        keys_info = {}
        for suffix in ['metadata', 'trending_keywords', 'word_cloud', 'news_feed']:
            key = f"{self.output_prefix}:{suffix}"
            exists = self.r.exists(key)
            if exists:
                size = len(self.r.get(key) or "")
                keys_info[key] = f"âœ“ å­˜åœ¨ ({size} bytes)"
            else:
                keys_info[key] = "âœ— ä¸å­˜åœ¨"
        
        return keys_info


# ä½¿ç”¨ç¤ºä¾‹
if __name__ == "__main__":
    import time

    redis_manager = RedisManager()

    # è·å–Redisä¿¡æ¯
    info = redis_manager.get_redis_info()
    if info:
        print("RedisæœåŠ¡å™¨ä¿¡æ¯:")
        for key, value in info.items():
            print(f"  {key}: {value}")

    # ä¿å­˜åŸå§‹æ•°æ®åˆ°æœ¬åœ°
    redis_manager.save_raw_data_to_local()

    # å‘å¸ƒå¤„ç†åçš„æ•°æ®
    redis_manager.publish_processed_data()

    # è·å–å¤„ç†åçš„æ•°æ®ï¼ˆæµ‹è¯•ï¼‰
    processed_data = redis_manager.get_processed_data()
    if processed_data:
        print("æˆåŠŸä»Redisè·å–å¤„ç†æ•°æ®")
        print(f"çƒ­é—¨å…³é”®è¯æ•°é‡: {len(processed_data['trending_keywords'])}")
        print(f"å†å²æ•°æ®å…³é”®è¯æ•°é‡: {len(processed_data['history_data'])}")