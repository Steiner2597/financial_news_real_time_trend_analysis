import json
import redis
import pandas as pd
from datetime import datetime, timedelta
from typing import List, Dict, Any, Optional
from config import CONFIG

# å¯¼å…¥ BERT é¢„æµ‹å™¨ï¼ˆå»¶è¿ŸåŠ è½½ï¼Œé¿å…å¯åŠ¨å¤±è´¥ï¼‰
try:
    from bert_predictor import get_predictor
    BERT_PREDICTOR_AVAILABLE = True
except Exception as e:
    print(f"âš ï¸  BERT é¢„æµ‹å™¨å¯¼å…¥å¤±è´¥: {e}")
    BERT_PREDICTOR_AVAILABLE = False


class DataLoader:
    """æ•°æ®åŠ è½½å™¨ - æ”¯æŒ Redis å®æ—¶æµå’Œæœ¬åœ°æ–‡ä»¶ä¸¤ç§æ¨¡å¼"""

    def __init__(self):
        self.config = CONFIG
        self._init_redis()

    def _init_redis(self):
        """åˆå§‹åŒ– Redis è¿æ¥åˆ° DB1ï¼ˆCleaner çš„è¾“å‡º DBï¼‰"""
        try:
            self.redis_client = redis.Redis(
                host=self.config["redis"]["host"],
                port=self.config["redis"]["port"],
                db=self.config["redis"]["input_db"],  # è¿æ¥åˆ° DB1
                decode_responses=True,
                socket_connect_timeout=5
            )
            self.redis_client.ping()
            print("âœ… Redis è¿æ¥æˆåŠŸï¼ˆDB1 - Cleaner è¾“å‡ºï¼‰")
        except Exception as e:
            print(f"âš ï¸  Redis è¿æ¥å¤±è´¥: {e}ï¼Œå°†ä½¿ç”¨æœ¬åœ°æ–‡ä»¶æ¨¡å¼")
            self.redis_client = None

    def load_data_from_redis(self) -> pd.DataFrame:
        """
        ä» Redis é˜Ÿåˆ—è¯»å–æ¸…æ´—åçš„æ•°æ®
        
        Returns:
            pd.DataFrame: æ¸…æ´—åçš„æ•°æ®
        """
        if not self.redis_client:
            print("âŒ Redis æœªè¿æ¥ï¼Œæ— æ³•ä»é˜Ÿåˆ—è¯»å–æ•°æ®")
            return pd.DataFrame()

        queue_name = self.config["redis"]["input_queue"]
        data_list = []
        
        try:
            # ç»Ÿè®¡åˆå§‹é˜Ÿåˆ—é•¿åº¦
            initial_queue_len = self.redis_client.llen(queue_name)
            print(f"ğŸ“Š Redis é˜Ÿåˆ— '{queue_name}' ä¸­æœ‰ {initial_queue_len} æ¡æ•°æ®")
            
            if initial_queue_len == 0:
                print(f"âš ï¸  è­¦å‘Šï¼šRedis é˜Ÿåˆ— '{queue_name}' ä¸ºç©º")
                return pd.DataFrame()
            
            # æ‰¹é‡è¯»å–é˜Ÿåˆ—ä¸­çš„æ‰€æœ‰æ•°æ®ï¼ˆéæ¶ˆè´¹æ¨¡å¼ï¼Œä¿ç•™å†å²æ•°æ®ï¼‰
            # ä½¿ç”¨ LRANGE è¯»å–å…¨éƒ¨æ•°æ®ï¼Œä¸åˆ é™¤
            raw_data = self.redis_client.lrange(queue_name, 0, -1)
            
            if not raw_data:
                print(f"âš ï¸  è­¦å‘Šï¼šRedis é˜Ÿåˆ— '{queue_name}' ä¸ºç©º")
                return pd.DataFrame()
            
            # è§£æ JSON æ•°æ®
            for item_json in raw_data:
                try:
                    item_data = json.loads(item_json)
                    data_list.append(item_data)
                except json.JSONDecodeError as e:
                    print(f"âš ï¸  JSON è§£æé”™è¯¯ï¼Œè·³è¿‡è¯¥æ•°æ®: {e}")
                    continue
            
            if data_list:
                print(f"âœ… æˆåŠŸä» Redis é˜Ÿåˆ—è¯»å– {len(data_list)} æ¡æ•°æ®ï¼ˆå†å²æ•°æ®ä¿ç•™ï¼‰")
                df = pd.DataFrame(data_list)
                return df
            else:
                print(f"âš ï¸  è­¦å‘Šï¼šRedis é˜Ÿåˆ— '{queue_name}' è¯»å–ç»“æœä¸ºç©º")
                return pd.DataFrame()

        except Exception as e:
            print(f"âŒ ä» Redis è¯»å–æ•°æ®å¤±è´¥: {e}")
            return pd.DataFrame()

    def load_data_from_file(self, file_path: str) -> pd.DataFrame:
        """
        ä»æœ¬åœ° CSV æ–‡ä»¶è¯»å–æ•°æ®ï¼ˆå¤‡ä»½æ–¹æ¡ˆï¼‰
        
        Args:
            file_path: CSV æ–‡ä»¶è·¯å¾„
            
        Returns:
            pd.DataFrame: æ•°æ®
        """
        try:
            print(f"ğŸ“‚ ä»æœ¬åœ°æ–‡ä»¶åŠ è½½æ•°æ®: {file_path}")
            df = pd.read_csv(file_path)
            print(f"âœ… æˆåŠŸåŠ è½½æœ¬åœ°æ–‡ä»¶ï¼Œå…± {len(df)} æ¡æ•°æ®")
            return df
        except FileNotFoundError:
            print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {file_path}")
            return pd.DataFrame()
        except Exception as e:
            print(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥: {e}")
            return pd.DataFrame()

    def load_data(self, file_path: str = None) -> pd.DataFrame:
        """
        åŠ è½½æ•°æ®ï¼ˆä¼˜å…ˆ Redisï¼Œå›é€€æœ¬åœ°æ–‡ä»¶ï¼‰
        
        Args:
            file_path: æœ¬åœ° CSV æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            
        Returns:
            pd.DataFrame: åŠ è½½çš„æ•°æ®
        """
        # ç­–ç•¥ 1: ä¼˜å…ˆå°è¯•ä» Redis è¯»å–
        print("\nğŸ”„ å°è¯•ä» Redis é˜Ÿåˆ—è¯»å–æ•°æ®...")
        df_redis = self.load_data_from_redis()
        
        if not df_redis.empty:
            print("âœ¨ ä½¿ç”¨ Redis å®æ—¶æ•°æ®å¤„ç†æ¨¡å¼")
            return df_redis
        
        # ç­–ç•¥ 2: å›é€€åˆ°æœ¬åœ° CSV æ–‡ä»¶
        csv_path = file_path or self.config.get("input_file", "input_data.csv")
        print(f"\nğŸ”„ Redis é˜Ÿåˆ—ä¸ºç©ºï¼Œå°è¯•æœ¬åœ°æ–‡ä»¶...")
        df_file = self.load_data_from_file(csv_path)
        
        if not df_file.empty:
            print("âœ¨ ä½¿ç”¨æœ¬åœ°æ–‡ä»¶å¤„ç†æ¨¡å¼")
            return df_file
        
        # éƒ½å¤±è´¥åˆ™è¿”å›ç©º
        print("âŒ æ— æ³•åŠ è½½ä»»ä½•æ•°æ®")
        return pd.DataFrame()

    def preprocess_data(self, df: pd.DataFrame) -> pd.DataFrame:
        """
        æ•°æ®é¢„å¤„ç†ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
        
        Args:
            df: è¾“å…¥æ•°æ®æ¡†
            
        Returns:
            pd.DataFrame: é¢„å¤„ç†åçš„æ•°æ®
        """
        if df.empty:
            return df

        # è½¬æ¢æ—¶é—´æ ¼å¼
        # ä¼˜å…ˆä½¿ç”¨ Cleaner æä¾›çš„ created_atï¼ˆISOæ ¼å¼ï¼‰ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä½¿ç”¨ timestamp
        if 'created_at' in df.columns:
            # Cleaner æä¾›äº† created_atï¼ˆISO æ ¼å¼å­—ç¬¦ä¸²ï¼‰ï¼Œè½¬æ¢ä¸º datetime
            df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce')
            # å¦‚æœæ²¡æœ‰ timestampï¼Œä» created_at åˆ›å»º
            if 'timestamp' not in df.columns:
                df['timestamp'] = df['created_at']
            else:
                # å¦‚æœ timestamp æ˜¯ Unix æ—¶é—´æˆ³ï¼Œè½¬æ¢å®ƒ
                if df['timestamp'].dtype in ['int64', 'float64']:
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s', errors='coerce')
                else:
                    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
        else:
            # Cleaner æ²¡æœ‰æä¾› created_atï¼Œä½¿ç”¨ timestamp
            if 'timestamp' not in df.columns:
                print("âš ï¸  è­¦å‘Šï¼šæ•°æ®ç¼ºå°‘ 'timestamp' å’Œ 'created_at' å­—æ®µï¼Œä½¿ç”¨å½“å‰æ—¶é—´")
                df['timestamp'] = datetime.now()
                df['created_at'] = df['timestamp']
            else:
                # è½¬æ¢ timestampï¼ˆUnixæ—¶é—´æˆ³ â†’ datetimeå¯¹è±¡ï¼‰
                if df['timestamp'].dtype in ['int64', 'float64']:
                    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s', errors='coerce')
                else:
                    df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
                # åˆ›å»º created_at = timestamp
                df['created_at'] = df['timestamp']

        # æ¸…ç†æ–‡æœ¬æ•°æ®ï¼ˆæå‰åšï¼Œå› ä¸º BERT é¢„æµ‹éœ€è¦ï¼‰
        if 'text' in df.columns:
            df['clean_text'] = df['text'].fillna('').apply(self._clean_text)
        elif 'content' in df.columns:
            df['clean_text'] = df['content'].fillna('').apply(self._clean_text)
        else:
            df['clean_text'] = ''

        # === ğŸ¤– BERT æƒ…æ„Ÿé¢„æµ‹é›†æˆ ===
        # ç¡®ä¿ sentiment åˆ—å­˜åœ¨
        if 'sentiment' not in df.columns:
            df['sentiment'] = ''
        
        # æ ‡å‡†åŒ–å·²æœ‰çš„æƒ…æ„Ÿæ ‡ç­¾
        sentiment_mapping = {
            'æ­£é¢': 'Bullish',
            'ä¸­æ€§': 'neutral',
            'è´Ÿé¢': 'Bearish',
            'Bullish': 'Bullish',
            'neutral': 'neutral',
            'Bearish': 'Bearish',
        }
        df['sentiment'] = df['sentiment'].map(sentiment_mapping).fillna(df['sentiment'])
        
        # ä½¿ç”¨ BERT é¢„æµ‹å™¨ä¸ºç¼ºå¤± sentiment çš„æ•°æ®å¡«å……
        if BERT_PREDICTOR_AVAILABLE:
            try:
                predictor = get_predictor()
                # ä½¿ç”¨åŸå§‹ text åˆ—è¿›è¡Œé¢„æµ‹ï¼ˆæ¯” clean_text ä¿ç•™æ›´å¤šä¿¡æ¯ï¼‰
                text_col = 'text' if 'text' in df.columns else 'content' if 'content' in df.columns else 'clean_text'
                # âœ… ä¼˜åŒ–4ï¼šä½¿ç”¨å»¶è¿Ÿ Redis æ›´æ–°ï¼ˆé€Ÿåº¦å¿« 5 å€ï¼‰
                defer_redis_update = self.config.get('bert', {}).get('defer_redis_update', True)
                df = predictor.fill_missing_sentiments(
                    df, 
                    text_column=text_col,
                    redis_client=self.redis_client,
                    queue_name=self.config['redis'].get('output_queue_name', 'clean_data_queue'),
                    defer_redis_update=defer_redis_update  # âœ… ä¼˜åŒ–ï¼šå»¶è¿Ÿæ›´æ–°
                )
                
                # âœ… å¦‚æœå¯ç”¨äº†å»¶è¿Ÿæ›´æ–°ï¼Œåœ¨è¿”å›å‰åˆ·æ–°å¾…å¤„ç†çš„ Redis æ›´æ–°
                if defer_redis_update and self.redis_client and hasattr(df, '_pending_redis_updates'):
                    print(f"\nğŸ“¤ å¤„ç†å®Œæˆï¼Œç°åœ¨åˆ·æ–°å¾…å¤„ç†çš„ Redis æ›´æ–°...")
                    predictor.flush_pending_redis_updates(df, self.redis_client)
            except Exception as e:
                print(f"âš ï¸  BERT é¢„æµ‹å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å€¼: {e}")
                import traceback
                traceback.print_exc()
                # å¡«å……ç©ºå€¼ä¸º neutral
                df['sentiment'] = df['sentiment'].fillna('neutral')
                df['sentiment'] = df['sentiment'].replace('', 'neutral')
        else:
            # å¦‚æœ BERT ä¸å¯ç”¨ï¼Œå¡«å……ä¸º neutral
            print("â„¹ï¸  BERT é¢„æµ‹å™¨ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤ neutral å¡«å……")
            df['sentiment'] = df['sentiment'].fillna('neutral')
            df['sentiment'] = df['sentiment'].replace('', 'neutral')

        return df

    def _clean_text(self, text: str) -> str:
        """æ¸…ç†æ–‡æœ¬"""
        if not isinstance(text, str):
            return ""

        # ç§»é™¤URL
        import re
        text = re.sub(r'http\S+', '', text)

        # ç§»é™¤è‚¡ç¥¨ä»£ç ï¼ˆå¦‚$ETH.Xï¼‰
        text = re.sub(r'\$\w+\.\w+', '', text)

        # ç§»é™¤ç‰¹æ®Šå­—ç¬¦ï¼Œä¿ç•™å­—æ¯æ•°å­—å’Œç©ºæ ¼
        text = re.sub(r'[^\w\s]', ' ', text)

        # è½¬æ¢ä¸ºå°å†™
        text = text.lower()

        # ç§»é™¤å¤šä½™ç©ºæ ¼
        text = ' '.join(text.split())

        return text

    def get_time_windows(self, df: pd.DataFrame) -> Dict[str, datetime]:
        """
        è·å–æ—¶é—´çª—å£ - åŸºäºæ•°æ®ä¸­çš„æœ€æ–°æ—¶é—´å‘å‰æ¨ 24 å°æ—¶
        
        âœ… å…³é”®ä¿®æ”¹ï¼šä½¿ç”¨ created_at è€Œä¸æ˜¯ timestampï¼Œå› ä¸º created_at æ˜¯ Cleaner ä¼ æ¥çš„çœŸå®æ—¶é—´å­—æ®µ
        
        å…³é”®é€»è¾‘ï¼š
        1. æ‰¾å‡º Cleaner ä¼ æ¥æ•°æ®çš„æœ€æ–°æ—¶é—´æˆ³ï¼ˆä½¿ç”¨ created_atï¼‰
        2. å°†è¯¥æ—¶é—´å‘ä¸Šå–æ•´åˆ°ä¸‹ä¸€ä¸ªæ•´ç‚¹ï¼ˆç¡®ä¿åŒ…å«å½“å‰å°æ—¶çš„æ‰€æœ‰æ•°æ®ï¼‰
        3. ä»è¯¥æ•´ç‚¹å‘å‰æ¨ 25 å°æ—¶ä½œä¸ºå†å²çª—å£èµ·ç‚¹ï¼ˆç¡®ä¿ç”Ÿæˆ 25 ä¸ªæ—¶é—´æ§½ï¼Œå³å®Œæ•´çš„ 24 å°æ—¶ï¼‰
        4. ä¿è¯ç”Ÿæˆçš„ history_data åŒ…å« 24 ä¸ªæ•´ç‚¹çš„æ•°æ®
        """
        # âœ… ä½¿ç”¨ created_at å­—æ®µï¼ˆCleaner çš„çœŸå®æ—¶é—´ï¼‰ï¼Œä¸ä½¿ç”¨ timestamp
        time_field = 'created_at' if 'created_at' in df.columns else 'timestamp'
        
        if df.empty or time_field not in df.columns:
            # è¿”å›é»˜è®¤æ—¶é—´çª—å£
            now = datetime.now()
            current_window_minutes = self.config.get("current_window_minutes", 60)
            return {
                'latest_time': now,
                'current_window_start': now - timedelta(minutes=current_window_minutes),
                'history_window_start': now - timedelta(hours=24)
            }

        # âœ… å…³é”®æ­¥éª¤ 1ï¼šè·å– Cleaner ä¼ æ¥çš„æœ€æ–°æ•°æ®æ—¶é—´ï¼ˆä» created_at è·å–ï¼‰
        latest_time = df[time_field].max()
        
        # âœ… å…³é”®æ­¥éª¤ 2ï¼šå°†æœ€æ–°æ—¶é—´å‘ä¸Šå–æ•´åˆ°ä¸‹ä¸€ä¸ªæ•´ç‚¹ï¼ˆç¡®ä¿åŒ…å«å½“å‰å°æ—¶ï¼‰
        # ä¾‹å¦‚ï¼š09:50 â†’ 10:00ï¼ˆä¸‹ä¸€ä¸ªæ•´ç‚¹ï¼‰
        if latest_time.minute > 0 or latest_time.second > 0 or latest_time.microsecond > 0:
            latest_hour = (latest_time + timedelta(hours=1)).replace(minute=0, second=0, microsecond=0)
        else:
            latest_hour = latest_time.replace(minute=0, second=0, microsecond=0)
        
        # âœ… å…³é”®æ­¥éª¤ 3ï¼šä»è¯¥æ•´ç‚¹å‘å‰æ¨ 25 å°æ—¶
        # è¿™æ ·ä¼šå¾—åˆ° [latest_hour - 25h, latest_hour] çš„æ—¶é—´èŒƒå›´ï¼Œç”Ÿæˆ 25 ä¸ª 1 å°æ—¶çš„æ§½
        # å³è¦†ç›–è¿‡å» 24 å°æ—¶çš„å®Œæ•´æ•°æ®
        history_window_start = latest_hour - timedelta(hours=25)
        
        # è¯»å–é…ç½®ä¸­çš„å½“å‰çª—å£è®¾ç½®
        current_window_minutes = self.config.get("current_window_minutes", 60)
        current_window_start = latest_time - timedelta(minutes=current_window_minutes)

        print(f"\nğŸ“… æ—¶é—´çª—å£è®¡ç®—ï¼ˆåŸºäºæœ€æ–°æ•°æ®æ—¶é—´ï¼‰:")
        print(f"  æ—¶é—´å­—æ®µ: {time_field} âœ…")
        print(f"  æœ€æ–°æ•°æ®æ—¶é—´: {latest_time.isoformat()}")
        print(f"  æœ€æ–°æ•´ç‚¹ï¼ˆå‘ä¸Šå–æ•´ï¼‰: {latest_hour.isoformat()}")
        print(f"  å†å²çª—å£: {history_window_start.isoformat()} ~ {latest_hour.isoformat()}")
        print(f"  æ—¶é—´è·¨åº¦: 25 å°æ—¶ï¼ˆç”Ÿæˆ 24 ä¸ªæ•´ç‚¹æ•°æ®ç‚¹ï¼‰")
        
        # éªŒè¯æ•°æ®è¦†ç›–æƒ…å†µ
        earliest_time = df[time_field].min()
        actual_hours = (latest_time - earliest_time).total_seconds() / 3600
        print(f"  å®é™…æ•°æ®: {earliest_time.isoformat()} ~ {latest_time.isoformat()}")
        print(f"  å®é™…è·¨åº¦: {actual_hours:.1f} å°æ—¶")

        return {
            'latest_time': latest_hour,  # âœ… è¿”å›å‘ä¸Šå–æ•´åçš„æ•´ç‚¹æ—¶é—´ä½œä¸ºç»“æŸç‚¹
            'current_window_start': current_window_start,
            'history_window_start': history_window_start
        }