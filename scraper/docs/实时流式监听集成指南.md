# 🚀 集成实时流式监听使用指南

## ✨ 新功能说明

现在 `run.bat` 的**循环模式（选项3）**支持自动启动 Reddit 实时流式监听！

### **工作原理**

```
run.bat → 选择 3 (循环模式)
    ↓
【批量爬虫】每10分钟运行一次
    ├─ Reddit (new/rising) - 延迟 1-2小时
    ├─ NewsAPI
    ├─ RSS
    └─ StockTwits
    
+【实时流监听】后台持续运行（并行）
    └─ Reddit Stream API - 延迟 < 1分钟
    
→ 两者同时运行，互相补充！
```

---

## 🎯 核心问题解答

### **Q1: Stream 只能抓当下新出现的吗？**
**答：是的！**
- ✅ **实时监听**：从程序启动后，捕获所有新发布的帖子
- ❌ **历史数据**：无法抓取启动前的帖子
- 💡 **解决方案**：批量爬虫负责抓历史，实时流负责抓新的

**示例：**
```
17:00 - 启动程序
17:01 - 新帖子发布 ✅ 实时流捕获（< 1分钟）
17:10 - 批量爬虫运行 ✅ 抓取过去1-2小时的帖子
16:50 - 的帖子 ✅ 批量爬虫抓取
16:00 - 的帖子 ✅ 批量爬虫抓取
```

---

### **Q2: Stream 用的设置和 reddit_crawler 一样吗？**
**答：完全一样！**

两者共享 `config.yaml` 中的 `reddit:` 配置：

| 配置项 | 说明 | 批量爬虫 | 实时流 |
|--------|------|---------|--------|
| `subreddits` | 监听哪些子版块 | ✅ | ✅ |
| `search_keywords` | 关键词过滤 | ✅ | ✅ |
| `post_filters` | 过滤条件 | ✅ | ✅ |
| `client_id/secret` | API认证 | ✅ | ✅ |

**示例配置：**
```yaml
reddit:
  subreddits:      # 两者都监听这些子版块
    - investing
    - finance
    - stocks
  
  search_keywords: # 两者都过滤这些关键词
    - earnings
    - IPO
  
  post_filters:    # 两者都应用这些过滤
    min_upvotes: 1
    min_comments: 1
```

---

## 🔧 配置方法

### **1. 启用实时流监听**

编辑 `config.yaml`：

```yaml
reddit:
  enabled: true
  
  # 🔥 新增：实时流式监听配置
  stream_enabled: true      # 改为 true 启用
  stream_duration: 600      # 每次运行10分钟后自动重启
  
  subreddits:               # 监听哪些子版块（批量+实时共用）
    - investing
    - finance
    - stocks
  
  search_keywords:          # 关键词过滤（批量+实时共用）
    - earnings
    - IPO
```

### **2. 禁用实时流监听**

如果只想用批量爬虫：

```yaml
reddit:
  stream_enabled: false     # 改为 false 禁用
```

---

## 🚀 使用方法

### **方式1：推荐使用（循环模式 + 实时流）**

```cmd
run.bat
→ 选择 3 (循环模式)
```

**效果：**
- ✅ 批量爬虫每10分钟运行一次（抓历史数据）
- ✅ 实时流后台持续运行（抓最新数据）
- ✅ 自动整合到同一个 Redis 队列
- ✅ Ctrl+C 停止时，两者都会优雅退出

**终端输出示例：**
```
========================================
启动循环模式 - 间隔: 600 秒 (10.0 分钟)
========================================

🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥
🔴 启动 Reddit 实时流式监听（后台运行）
🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥
  • 监听新帖子：< 1分钟延迟
  • 与批量爬虫并行运行
  • 后台持续运行，无需手动操作
🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥🔥

✅ 实时流式监听已在后台启动

按 Ctrl+C 停止
========================================

第 1 次运行 - 2025-11-03 18:00:00
========================================

运行 REDDIT 爬虫
...
✅ 实时捕获: r/investing | Tesla reports record earnings... | upvotes=245
...

抓取任务统计
========================================
Reddit批量:  帖子 50, 评论 150, 错误 0
Reddit实时:  帖子 12, 错误 0 🔴 运行中
NewsAPI:     文章 25, 错误 0
RSS:         文章 30, 错误 0
...
```

---

### **方式2：单次运行（不启用实时流）**

```cmd
run.bat
→ 选择 2 (单次运行)
```

**效果：**
- ✅ 只运行批量爬虫一次
- ❌ 不启动实时流监听
- 💡 适合测试或手动抓取

---

### **方式3：仅实时流（独立运行）**

如果只想测试实时流：

```cmd
start_stream_crawler.bat
```

**效果：**
- ✅ 只运行实时流监听
- ❌ 不运行批量爬虫
- 💡 适合专门监控突发事件

---

## 📊 数据流向

两种模式的数据最终都存入同一个地方：

```
【批量爬虫】
Reddit Crawler → Reddit API (new/rising)
    ↓ 延迟 1-2小时
    ↓ 每10分钟抓取一次
    ↓
【实时流监听】
Stream Crawler → Reddit Stream API
    ↓ 延迟 < 1分钟
    ↓ 持续监听
    ↓
【统一存储】
Redis DB0: data_queue (共享队列)
    ↓
【后续处理】
Cleaner → Processor → Visualization
```

---

## 🎯 最佳实践

### **推荐配置：混合模式**

```yaml
reddit:
  enabled: true
  stream_enabled: true      # 启用实时流
  
  subreddits:               # 监听重要的财经子版块
    - investing
    - finance
    - stocks
    - wallstreetbets
  
  post_filters:             # 适当的过滤条件
    min_upvotes: 1          # 放宽条件，抓更多数据
    min_comments: 1
  
  posts_limit: 50           # 批量爬虫每次抓50条
  stream_duration: 600      # 实时流每10分钟重启

crawler_control:
  loop_interval: 600        # 批量爬虫每10分钟运行
```

---

## ⚙️ 高级配置

### **调整实时流运行时长**

默认每10分钟重启一次（避免长连接问题）：

```yaml
reddit:
  stream_duration: 600      # 改为更长/更短的时间（秒）
```

### **关键词过滤**

实时流和批量爬虫都会应用：

```yaml
reddit:
  search_keywords:
    - earnings              # 财报
    - IPO                   # 新股上市
    - "breaking"            # 突发新闻
    - "SEC investigation"   # 监管调查
```

### **过滤条件**

```yaml
reddit:
  post_filters:
    min_upvotes: 5          # 至少5个赞
    min_comments: 2         # 至少2条评论
```

---

## 🐛 故障排查

### **问题1：实时流未启动**

**现象：** 只看到批量爬虫运行，没有实时流

**检查：**
```yaml
reddit:
  enabled: true             # 确保启用
  stream_enabled: true      # 确保启用
```

**日志输出：**
```
○ Reddit 实时流式爬虫已禁用（在 config.yaml 中设置 reddit.stream_enabled: true 启用）
```

---

### **问题2：实时流频繁重启**

**现象：** 看到 "🔄 实时流监听重启中..."

**原因：** 这是正常行为！每10分钟自动重启，避免长连接问题

**调整：**
```yaml
reddit:
  stream_duration: 1800     # 改为30分钟
```

---

### **问题3：捕获数据过少**

**原因1：** 过滤条件太严格

**解决：**
```yaml
reddit:
  post_filters:
    min_upvotes: 0          # 放宽条件
    min_comments: 0
```

**原因2：** 关键词过滤太严格

**解决：**
```yaml
reddit:
  search_keywords: []       # 留空 = 不过滤
```

---

## 📈 性能对比

| 指标 | 仅批量爬虫 | 仅实时流 | 混合模式 |
|------|-----------|---------|---------|
| 延迟时间 | 1-2小时 | < 1分钟 | < 1分钟（最佳） |
| 数据完整性 | ⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐⭐⭐⭐⭐ |
| CPU占用 | 低 | 中 | 中 |
| 内存占用 | 低 | 中 | 中 |
| 适用场景 | 历史分析 | 实时监控 | 全面覆盖 |

---

## 📝 总结

✅ **实时流 = 捕获最新的**（启动后的新帖）  
✅ **批量爬 = 补充历史的**（过去1-2小时的帖）  
✅ **配置共享**（同一个 config.yaml）  
✅ **数据共享**（同一个 Redis 队列）  
✅ **自动启动**（循环模式下）  

**一键启动，全自动运行！** 🎉
