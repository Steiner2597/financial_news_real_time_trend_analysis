"""
Reddit å®æ—¶æµå¼çˆ¬è™« - çœŸæ­£çš„å®æ—¶æ•°æ®
ä½¿ç”¨ PRAW Stream APIï¼Œå»¶è¿Ÿ < 1åˆ†é’Ÿ
"""
import sys
import time
import praw
import prawcore
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Set

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, str(Path(__file__).parent.parent))

from utils.logger import setup_logger
from utils.redis_client import RedisClient

logger = setup_logger('reddit_stream')


class RedditStreamCrawler:
    """
    Reddit å®æ—¶æµå¼çˆ¬è™«
    
    ç‰¹ç‚¹ï¼š
    - çœŸæ­£å®æ—¶ï¼ˆå»¶è¿Ÿ < 1åˆ†é’Ÿï¼‰
    - æŒç»­ç›‘å¬ï¼Œæ— éœ€è½®è¯¢
    - é€‚åˆå…³é”®è¯ç›‘æ§å’Œçƒ­ç‚¹è¿½è¸ª
    """
    
    def __init__(self, config: dict, redis_client: RedisClient):
        """
        åˆå§‹åŒ–å®æ—¶æµå¼çˆ¬è™«
        
        Args:
            config: Reddit é…ç½®å­—å…¸
            redis_client: Redis å®¢æˆ·ç«¯å®ä¾‹
        """
        self.config = config
        self.redis_client = redis_client
        
        try:
            self.reddit = praw.Reddit(
                client_id=config['client_id'],
                client_secret=config['client_secret'],
                user_agent=config['user_agent']
            )
            logger.info("Reddit Stream API åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"Reddit API åˆå§‹åŒ–å¤±è´¥: {e}")
            raise
        
        self.subreddits = config.get('subreddits', ['investing', 'finance'])
        self.keywords = config.get('search_keywords', [])
        self.post_filters = config.get('post_filters', {})
        
        # å·²å¤„ç†çš„å¸–å­IDï¼ˆå†…å­˜ç¼“å­˜ï¼Œé¿å…é‡å¤å¤„ç†ï¼‰
        self.processed_ids: Set[str] = set()
        self.max_cache_size = 10000
    
    def stream_submissions(self, duration_seconds: int = None, stop_flag: callable = None):
        """
        å®æ—¶æµå¼ç›‘å¬æ–°å¸–å­ï¼ˆçœŸæ­£çš„å®æ—¶ï¼Œå»¶è¿Ÿ < 1åˆ†é’Ÿï¼‰
        
        Args:
            duration_seconds: è¿è¡Œæ—¶é•¿ï¼ˆç§’ï¼‰ï¼ŒNone=æ— é™è¿è¡Œç›´åˆ°æ‰‹åŠ¨åœæ­¢
            stop_flag: åœæ­¢æ ‡å¿—å›è°ƒå‡½æ•°ï¼Œè¿”å› True æ—¶åœæ­¢ç›‘å¬
        
        Returns:
            dict: ç»Ÿè®¡ä¿¡æ¯
        """
        stats = {'posts': 0, 'comments': 0, 'errors': 0}
        start_time = time.time()
        
        # ç»„åˆæ‰€æœ‰è¦ç›‘å¬çš„å­ç‰ˆå—
        subreddit_str = '+'.join(self.subreddits)
        logger.info(f"ğŸ”´ å¼€å§‹å®æ—¶æµå¼ç›‘å¬: r/{subreddit_str}")
        
        if duration_seconds:
            logger.info(f"â±ï¸  è¿è¡Œæ—¶é•¿: {duration_seconds}ç§’ ({duration_seconds//60:.1f}åˆ†é’Ÿ)")
        else:
            logger.info(f"â±ï¸  è¿è¡Œæ¨¡å¼: æŒç»­ç›‘å¬ï¼ˆæŒ‰ Ctrl+C åœæ­¢ï¼‰")
        
        try:
            subreddit = self.reddit.subreddit(subreddit_str)
            
            # ğŸ”¥ æ ¸å¿ƒï¼šstream.submissions() å®æ—¶ç›‘å¬æ–°å¸–å­
            for submission in subreddit.stream.submissions(skip_existing=True):
                # ğŸ”¥ æ£€æŸ¥å¤–éƒ¨åœæ­¢ä¿¡å·
                if stop_flag and stop_flag():
                    logger.info(f"ğŸ›‘ æ”¶åˆ°åœæ­¢ä¿¡å·ï¼Œé€€å‡ºç›‘å¬")
                    break
                
                # æ£€æŸ¥æ˜¯å¦è¶…æ—¶ï¼ˆå¦‚æœè®¾ç½®äº†æ—¶é•¿é™åˆ¶ï¼‰
                if duration_seconds and time.time() - start_time > duration_seconds:
                    logger.info(f"â° è¾¾åˆ°è¿è¡Œæ—¶é•¿é™åˆ¶ï¼Œåœæ­¢ç›‘å¬")
                    break
                
                try:
                    # å»é‡æ£€æŸ¥ï¼ˆå†…å­˜ + Redisï¼‰
                    if submission.id in self.processed_ids:
                        continue
                    if self._is_post_processed(submission.id):
                        self.processed_ids.add(submission.id)
                        continue
                    
                    # å…³é”®è¯è¿‡æ»¤ï¼ˆå¯é€‰ï¼‰
                    if self.keywords and not self._contains_keywords(submission):
                        continue
                    
                    # æå–æ•°æ®
                    post_data = self._extract_post_data(submission)
                    if not post_data:
                        continue
                    
                    # åº”ç”¨è¿‡æ»¤æ¡ä»¶
                    if not self._apply_post_filters(post_data):
                        continue
                    
                    # ä¿å­˜åˆ° Redis
                    if self.redis_client.push_data(post_data):
                        stats['posts'] += 1
                        self.processed_ids.add(submission.id)
                        self._mark_post_processed(submission.id)
                        
                        # ğŸ”¥ ç”¨ä¸åŒå‰ç¼€åŒºåˆ†å®æ—¶æµå’Œæ‰¹é‡çˆ¬è™«
                        logger.info(
                            f"ğŸ”´ [å®æ—¶æµ] r/{submission.subreddit.display_name} | "
                            f"{submission.title[:45]}... | "
                            f"ğŸ‘{submission.score}"
                        )
                        
                        # å¯é€‰ï¼šç«‹å³æŠ“å–è¯„è®º
                        # comments_count = self._crawl_comments(submission)
                        # stats['comments'] += comments_count
                    
                    # æ¸…ç†ç¼“å­˜ï¼ˆé˜²æ­¢å†…å­˜æº¢å‡ºï¼‰
                    if len(self.processed_ids) > self.max_cache_size:
                        self.processed_ids.clear()
                        logger.info("ğŸ§¹ æ¸…ç†å†…å­˜ç¼“å­˜")
                
                except prawcore.ResponseException as e:
                    logger.error(f"Reddit API é”™è¯¯: {e}")
                    stats['errors'] += 1
                    time.sleep(5)
                except Exception as e:
                    logger.error(f"å¤„ç†å¸–å­æ—¶å‡ºé”™: {e}")
                    stats['errors'] += 1
        
        except KeyboardInterrupt:
            logger.info("âš ï¸  ç”¨æˆ·ä¸­æ–­ç›‘å¬")
        except Exception as e:
            logger.error(f"æµå¼ç›‘å¬å¤±è´¥: {e}")
            stats['errors'] += 1
        
        elapsed = time.time() - start_time
        hours = elapsed / 3600
        logger.info(
            f"ğŸ“Š å®æ—¶ç›‘å¬å®Œæˆ - "
            f"è¿è¡Œæ—¶é•¿: {elapsed:.0f}ç§’ ({hours:.2f}å°æ—¶) | "
            f"æ–°å¸–: {stats['posts']} | "
            f"é”™è¯¯: {stats['errors']}"
        )
        return stats
    
    def stream_comments(self, duration_seconds: int = 600):
        """
        å®æ—¶æµå¼ç›‘å¬æ–°è¯„è®º
        
        Args:
            duration_seconds: è¿è¡Œæ—¶é•¿ï¼ˆç§’ï¼‰
        
        Returns:
            dict: ç»Ÿè®¡ä¿¡æ¯
        """
        stats = {'comments': 0, 'errors': 0}
        start_time = time.time()
        
        subreddit_str = '+'.join(self.subreddits)
        logger.info(f"ğŸ’¬ å¼€å§‹å®æ—¶æµå¼ç›‘å¬è¯„è®º: r/{subreddit_str}")
        
        try:
            subreddit = self.reddit.subreddit(subreddit_str)
            
            # ğŸ”¥ å®æ—¶ç›‘å¬æ–°è¯„è®º
            for comment in subreddit.stream.comments(skip_existing=True):
                if time.time() - start_time > duration_seconds:
                    break
                
                try:
                    # å»é‡æ£€æŸ¥
                    if comment.id in self.processed_ids:
                        continue
                    if self._is_comment_processed(comment.id):
                        self.processed_ids.add(comment.id)
                        continue
                    
                    # å…³é”®è¯è¿‡æ»¤
                    if self.keywords and not self._comment_contains_keywords(comment):
                        continue
                    
                    # æå–è¯„è®ºæ•°æ®
                    comment_data = self._extract_comment_data(comment)
                    if not comment_data:
                        continue
                    
                    # éªŒè¯æœ‰æ•ˆæ€§
                    if not self._is_valid_comment(comment_data):
                        continue
                    
                    # ä¿å­˜
                    if self.redis_client.push_data(comment_data):
                        stats['comments'] += 1
                        self.processed_ids.add(comment.id)
                        self._mark_comment_processed(comment.id)
                        
                        logger.info(
                            f"ğŸ’¬ å®æ—¶è¯„è®º: r/{comment.subreddit.display_name} | "
                            f"{comment.body[:50]}..."
                        )
                    
                    # æ¸…ç†ç¼“å­˜
                    if len(self.processed_ids) > self.max_cache_size:
                        self.processed_ids.clear()
                
                except Exception as e:
                    logger.error(f"å¤„ç†è¯„è®ºæ—¶å‡ºé”™: {e}")
                    stats['errors'] += 1
        
        except KeyboardInterrupt:
            logger.info("âš ï¸  ç”¨æˆ·ä¸­æ–­ç›‘å¬")
        except Exception as e:
            logger.error(f"æµå¼ç›‘å¬è¯„è®ºå¤±è´¥: {e}")
            stats['errors'] += 1
        
        logger.info(f"ğŸ“Š è¯„è®ºç›‘å¬å®Œæˆ - æ–°è¯„è®º: {stats['comments']}")
        return stats
    
    def _contains_keywords(self, submission) -> bool:
        """æ£€æŸ¥å¸–å­æ˜¯å¦åŒ…å«å…³é”®è¯"""
        if not self.keywords:
            return True
        
        text = f"{submission.title} {submission.selftext}".lower()
        return any(kw.lower() in text for kw in self.keywords)
    
    def _comment_contains_keywords(self, comment) -> bool:
        """æ£€æŸ¥è¯„è®ºæ˜¯å¦åŒ…å«å…³é”®è¯"""
        if not self.keywords:
            return True
        
        text = comment.body.lower()
        return any(kw.lower() in text for kw in self.keywords)
    
    def _is_post_processed(self, post_id: str) -> bool:
        """æ£€æŸ¥å¸–å­æ˜¯å¦å·²å¤„ç†"""
        try:
            key = f"reddit:post:{post_id}"
            return self.redis_client.client.exists(key) > 0
        except:
            return False
    
    def _mark_post_processed(self, post_id: str):
        """æ ‡è®°å¸–å­ä¸ºå·²å¤„ç†"""
        try:
            key = f"reddit:post:{post_id}"
            self.redis_client.client.setex(key, 604800, "1")  # 7å¤©
        except:
            pass
    
    def _is_comment_processed(self, comment_id: str) -> bool:
        """æ£€æŸ¥è¯„è®ºæ˜¯å¦å·²å¤„ç†"""
        try:
            key = f"reddit:comment:{comment_id}"
            return self.redis_client.client.exists(key) > 0
        except:
            return False
    
    def _mark_comment_processed(self, comment_id: str):
        """æ ‡è®°è¯„è®ºä¸ºå·²å¤„ç†"""
        try:
            key = f"reddit:comment:{comment_id}"
            self.redis_client.client.setex(key, 604800, "1")  # 7å¤©
        except:
            pass
    
    def _is_valid_comment(self, comment_data: Dict) -> bool:
        """éªŒè¯è¯„è®ºæœ‰æ•ˆæ€§"""
        text = comment_data.get('text', '').strip()
        if text in ['[deleted]', '[removed]', '']:
            return False
        if len(text) < 3:
            return False
        return True
    
    def _apply_post_filters(self, post_data: Dict) -> bool:
        """åº”ç”¨å¸–å­è¿‡æ»¤æ¡ä»¶"""
        min_upvotes = self.post_filters.get('min_upvotes', 0)
        min_comments = self.post_filters.get('min_comments', 0)
        
        if post_data['score'] < min_upvotes:
            return False
        if post_data['num_comments'] < min_comments:
            return False
        return True
    
    def _extract_post_data(self, submission) -> Dict[str, Any]:
        """æå–å¸–å­æ•°æ®"""
        try:
            text = submission.title
            if submission.selftext:
                text += "\n\n" + submission.selftext
            
            return {
                'text': text,
                'source': 'reddit_stream',
                'timestamp': int(submission.created_utc),
                'url': f"https://www.reddit.com{submission.permalink}",
                'subreddit': submission.subreddit.display_name,
                'post_id': submission.id,
                'author': str(submission.author) if submission.author else '[deleted]',
                'score': submission.score,
                'upvote_ratio': getattr(submission, 'upvote_ratio', 0),
                'num_comments': submission.num_comments,
                'is_self': submission.is_self,
                'title': submission.title,
                'selftext': submission.selftext if submission.selftext else ''
            }
        except Exception as e:
            logger.error(f"æå–å¸–å­æ•°æ®å¤±è´¥: {e}")
            return None
    
    def _extract_comment_data(self, comment) -> Dict[str, Any]:
        """æå–è¯„è®ºæ•°æ®"""
        try:
            return {
                'text': comment.body,
                'source': 'reddit_stream_comment',
                'timestamp': int(comment.created_utc),
                'url': f"https://www.reddit.com{comment.permalink}",
                'subreddit': comment.subreddit.display_name,
                'comment_id': comment.id,
                'author': str(comment.author) if comment.author else '[deleted]',
                'score': comment.score,
                'parent_id': comment.parent_id,
                'link_id': comment.link_id
            }
        except Exception as e:
            logger.error(f"æå–è¯„è®ºæ•°æ®å¤±è´¥: {e}")
            return None


def main():
    """æµ‹è¯•å®æ—¶æµå¼çˆ¬è™«"""
    import yaml
    import signal
    import sys
    
    # ç¡®ä¿åœ¨æ­£ç¡®çš„ç›®å½•
    config_path = Path(__file__).parent.parent / 'config.yaml'
    with open(config_path, 'r', encoding='utf-8') as f:
        config = yaml.safe_load(f)
    
    redis_client = RedisClient(**config['redis'])
    crawler = RedditStreamCrawler(config['reddit'], redis_client)
    
    # ğŸ”¥ è®¾ç½®åœæ­¢æ ‡å¿—
    stop_requested = False
    
    def signal_handler(sig, frame):
        nonlocal stop_requested
        logger.info("\nâš ï¸  æ”¶åˆ°åœæ­¢ä¿¡å· (Ctrl+C)")
        stop_requested = True
    
    signal.signal(signal.SIGINT, signal_handler)
    
    # ğŸ”¥ æ— é™è¿è¡Œç›´åˆ°æŒ‰ Ctrl+C
    logger.info("ğŸ”´ å¯åŠ¨å®æ—¶ç›‘å¬ï¼ˆæŒç»­è¿è¡Œï¼ŒæŒ‰ Ctrl+C åœæ­¢ï¼‰...")
    try:
        stats = crawler.stream_submissions(
            duration_seconds=None,  # None = æ— é™è¿è¡Œ
            stop_flag=lambda: stop_requested  # ğŸ”¥ æ£€æŸ¥åœæ­¢æ ‡å¿—
        )
        logger.info(f"âœ… å®Œæˆ: {stats}")
    except Exception as e:
        logger.error(f"âŒ è¿è¡Œå‡ºé”™: {e}")
    finally:
        redis_client.close()
        logger.info("âœ… ç›‘å¬å·²åœæ­¢")


if __name__ == '__main__':
    main()
